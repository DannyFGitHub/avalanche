<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>avalanche.benchmarks.scenarios &mdash; Avalanche 0.1 documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/mystyle.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex/" />
    <link rel="search" title="Search" href="../../../../search/" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../">
            <img src="../../../../_static/avalanche_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Avalanche API:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../../">API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche</span></code></a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../../#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="../"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../evaluation/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../logging/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.logging</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../models/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.models</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../training/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../#submodules">Submodules</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../core/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.core</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../#package-contents">Package Contents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../#avalanche.__version__">__version__</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../">Avalanche</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../" class="icon icon-home"></a> &raquo;</li>
      <li><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios</span></code></li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../_sources/autoapi/avalanche/benchmarks/scenarios/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-avalanche.benchmarks.scenarios">
<span id="avalanche-benchmarks-scenarios"></span><h1><a class="reference internal" href="#module-avalanche.benchmarks.scenarios" title="avalanche.benchmarks.scenarios"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios</span></code></a><a class="headerlink" href="#module-avalanche.benchmarks.scenarios" title="Permalink to this headline"></a></h1>
<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline"></a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="new_classes/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.new_classes</span></code></a><ul>
<li class="toctree-l2"><a class="reference internal" href="new_classes/nc_scenario/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.new_classes.nc_scenario</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="new_classes/nc_utils/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.new_classes.nc_utils</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="new_instances/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.new_instances</span></code></a><ul>
<li class="toctree-l2"><a class="reference internal" href="new_instances/ni_scenario/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.new_instances.ni_scenario</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="new_instances/ni_utils/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.new_instances.ni_utils</span></code></a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline"></a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="generic_benchmark_creation/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.generic_benchmark_creation</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="generic_cl_scenario/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.generic_cl_scenario</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="generic_definitions/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.generic_definitions</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="generic_scenario_creation/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.generic_scenario_creation</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="lazy_dataset_sequence/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.lazy_dataset_sequence</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="scenario_utils/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.scenario_utils</span></code></a></li>
</ul>
</div>
</section>
<section id="package-contents">
<h2>Package Contents<a class="headerlink" href="#package-contents" title="Permalink to this headline"></a></h2>
<section id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this headline"></a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.scenarios.Experience" title="avalanche.benchmarks.scenarios.Experience"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Experience</span></code></a></p></td>
<td><p>Definition of an experience. An experience contains a set of patterns</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.scenarios.ScenarioStream" title="avalanche.benchmarks.scenarios.ScenarioStream"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ScenarioStream</span></code></a></p></td>
<td><p>A scenario stream describes a sequence of incremental experiences.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.scenarios.StreamUserDef" title="avalanche.benchmarks.scenarios.StreamUserDef"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StreamUserDef</span></code></a></p></td>
<td><p>Typed version of namedtuple.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.scenarios.StreamDef" title="avalanche.benchmarks.scenarios.StreamDef"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StreamDef</span></code></a></p></td>
<td><p>Typed version of namedtuple.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericCLScenario" title="avalanche.benchmarks.scenarios.GenericCLScenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a></p></td>
<td><p>Base implementation of a Continual Learning benchmark instance.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericScenarioStream" title="avalanche.benchmarks.scenarios.GenericScenarioStream"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GenericScenarioStream</span></code></a></p></td>
<td><p>A scenario stream describes a sequence of incremental experiences.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.scenarios.AbstractExperience" title="avalanche.benchmarks.scenarios.AbstractExperience"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AbstractExperience</span></code></a></p></td>
<td><p>Definition of a learning experience. A learning experience contains a set of</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericExperience" title="avalanche.benchmarks.scenarios.GenericExperience"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GenericExperience</span></code></a></p></td>
<td><p>Definition of a learning experience based on a <a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericCLScenario" title="avalanche.benchmarks.scenarios.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.scenarios.NCScenario" title="avalanche.benchmarks.scenarios.NCScenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NCScenario</span></code></a></p></td>
<td><p>This class defines a &quot;New Classes&quot; scenario. Once created, an instance</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.scenarios.NCExperience" title="avalanche.benchmarks.scenarios.NCExperience"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NCExperience</span></code></a></p></td>
<td><p>Defines a &quot;New Classes&quot; experience. It defines fields to obtain the current</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.scenarios.NIScenario" title="avalanche.benchmarks.scenarios.NIScenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NIScenario</span></code></a></p></td>
<td><p>This class defines a &quot;New Instance&quot; scenario.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.scenarios.NIExperience" title="avalanche.benchmarks.scenarios.NIExperience"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NIExperience</span></code></a></p></td>
<td><p>Defines a &quot;New Instances&quot; experience. It defines fields to obtain the</p></td>
</tr>
</tbody>
</table>
</section>
<section id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Permalink to this headline"></a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.scenarios.create_multi_dataset_generic_scenario" title="avalanche.benchmarks.scenarios.create_multi_dataset_generic_scenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">create_multi_dataset_generic_scenario</span></code></a>(train_dataset_list: Sequence[SupportedDataset], test_dataset_list: Sequence[SupportedDataset], task_labels: Sequence[int], complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, eval_transform=None, eval_target_transform=None, dataset_type: AvalancheDatasetType = None) → GenericCLScenario</p></td>
<td><p>This helper function is DEPRECATED in favor of</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.scenarios.create_generic_scenario_from_filelists" title="avalanche.benchmarks.scenarios.create_generic_scenario_from_filelists"><code class="xref py py-obj docutils literal notranslate"><span class="pre">create_generic_scenario_from_filelists</span></code></a>(root: Union[str, Path], train_file_lists: Sequence[Union[str, Path]], test_file_lists: Union[Union[str, Path], Sequence[Union[str, Path]]], task_labels: Sequence[int], complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, eval_transform=None, eval_target_transform=None) → GenericCLScenario</p></td>
<td><p>This helper function is DEPRECATED in favor of</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.scenarios.create_generic_scenario_from_paths" title="avalanche.benchmarks.scenarios.create_generic_scenario_from_paths"><code class="xref py py-obj docutils literal notranslate"><span class="pre">create_generic_scenario_from_paths</span></code></a>(train_list_of_files: Sequence[Sequence[FileAndLabel]], test_list_of_files: Union[Sequence[FileAndLabel], Sequence[Sequence[FileAndLabel]]], task_labels: Sequence[int], complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, eval_transform=None, eval_target_transform=None, dataset_type: AvalancheDatasetType = AvalancheDatasetType.UNDEFINED) → GenericCLScenario</p></td>
<td><p>This helper function is DEPRECATED in favor of</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.scenarios.create_generic_scenario_from_tensor_lists" title="avalanche.benchmarks.scenarios.create_generic_scenario_from_tensor_lists"><code class="xref py py-obj docutils literal notranslate"><span class="pre">create_generic_scenario_from_tensor_lists</span></code></a>(train_tensors: Sequence[Sequence[Any]], test_tensors: Sequence[Sequence[Any]], task_labels: Sequence[int], *, complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, eval_transform=None, eval_target_transform=None, dataset_type: AvalancheDatasetType = None) → GenericCLScenario</p></td>
<td><p>This helper function is DEPRECATED in favor of</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.scenarios.create_generic_scenario_from_tensors" title="avalanche.benchmarks.scenarios.create_generic_scenario_from_tensors"><code class="xref py py-obj docutils literal notranslate"><span class="pre">create_generic_scenario_from_tensors</span></code></a>(train_data_x: Sequence[Any], train_data_y: Sequence[Sequence[SupportsInt]], test_data_x: Union[Any, Sequence[Any]], test_data_y: Union[Any, Sequence[Sequence[SupportsInt]]], task_labels: Sequence[int], complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, eval_transform=None, eval_target_transform=None, dataset_type: AvalancheDatasetType = AvalancheDatasetType.UNDEFINED) → GenericCLScenario</p></td>
<td><p>This helper function is DEPRECATED in favor of</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.Experience">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">Experience</span></span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_definitions/#Experience"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.Experience" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Protocol[TScenario,</span> <span class="pre">TScenarioStream]</span></code></p>
<p>Definition of an experience. An experience contains a set of patterns
which has become available at a particular time instant. The content and
size of an Experience is defined by the specific benchmark that creates the
IExperience instance.</p>
<p>For instance, an experience of a New Classes scenario will contain all
patterns belonging to a subset of classes of the original training set. An
experience of a New Instance scenario will contain patterns from previously
seen classes.</p>
<p>Experiences of Single Incremental Task (a.k.a. task-free) scenarios are
usually called “batches” while in Multi Task scenarios an Experience is
usually associated to a “task”. Finally, in a Multi Incremental Task
scenario the Experience may be composed by patterns from different tasks.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.Experience.origin_stream">
<span class="sig-name descname"><span class="pre">origin_stream</span></span><em class="property"> <span class="pre">:TScenarioStream</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.Experience.origin_stream" title="Permalink to this definition"></a></dt>
<dd><p>A reference to the original stream from which this experience was obtained.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.Experience.benchmark">
<span class="sig-name descname"><span class="pre">benchmark</span></span><em class="property"> <span class="pre">:TScenario</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.Experience.benchmark" title="Permalink to this definition"></a></dt>
<dd><p>A reference to the benchmark.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.Experience.current_experience">
<span class="sig-name descname"><span class="pre">current_experience</span></span><em class="property"> <span class="pre">:int</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.Experience.current_experience" title="Permalink to this definition"></a></dt>
<dd><p>This is an incremental, 0-indexed, value used to keep track of the position
of current experience in the original stream.</p>
<p>Beware that this value only describes the experience position in the
original stream and may be unrelated to the order in which the strategy will
encounter experiences.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.Experience.dataset">
<span class="sig-name descname"><span class="pre">dataset</span></span><em class="property"> <span class="pre">:AvalancheDataset</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.Experience.dataset" title="Permalink to this definition"></a></dt>
<dd><p>The dataset containing the patterns available in this experience.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.Experience.task_labels">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">task_labels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.Experience.task_labels" title="Permalink to this definition"></a></dt>
<dd><p>This list will contain the unique task labels of the patterns contained
in this experience. In the most common scenarios this will be a list
with a single value. Note: for scenarios that don’t produce task labels,
a placeholder task label value like 0 is usually set to each pattern
(see the description of the originating scenario for details).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.Experience.task_label">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">task_label</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.Experience.task_label" title="Permalink to this definition"></a></dt>
<dd><p>The task label. This value will never have value “None”. However,
for scenarios that don’t produce task labels a placeholder value like 0
is usually set. Beware that this field is meant as a shortcut to obtain
a unique task label: it assumes that only patterns labeled with a
single task label are present. If this experience contains patterns from
multiple tasks, accessing this property will result in an exception.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.Experience.scenario">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">scenario</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#avalanche.benchmarks.scenarios.TScenario" title="avalanche.benchmarks.scenarios.TScenario"><span class="pre">TScenario</span></a></span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.Experience.scenario" title="Permalink to this definition"></a></dt>
<dd><p>This property is DEPRECATED, use self.benchmark instead.</p>
</dd></dl>

</dd></dl>

<dl class="py data">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.TExperience">
<span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">TExperience</span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.TExperience" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py data">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.TScenario">
<span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">TScenario</span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.TScenario" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.ScenarioStream">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">ScenarioStream</span></span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_definitions/#ScenarioStream"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.ScenarioStream" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Protocol[TScenario,</span> <span class="pre">TExperience]</span></code></p>
<p>A scenario stream describes a sequence of incremental experiences.
Experiences are described as <code class="xref py py-class docutils literal notranslate"><span class="pre">IExperience</span></code> instances. They contain a
set of patterns which has become available at a particular time instant
along with any optional, scenario specific, metadata.</p>
<p>Most scenario expose two different streams: the training stream and the test
stream.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.ScenarioStream.name">
<span class="sig-name descname"><span class="pre">name</span></span><em class="property"> <span class="pre">:str</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.ScenarioStream.name" title="Permalink to this definition"></a></dt>
<dd><p>The name of the stream.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.ScenarioStream.benchmark">
<span class="sig-name descname"><span class="pre">benchmark</span></span><em class="property"> <span class="pre">:TScenario</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.ScenarioStream.benchmark" title="Permalink to this definition"></a></dt>
<dd><p>A reference to the scenario this stream belongs to.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.ScenarioStream.scenario">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">scenario</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#avalanche.benchmarks.scenarios.TScenario" title="avalanche.benchmarks.scenarios.TScenario"><span class="pre">TScenario</span></a></span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.ScenarioStream.scenario" title="Permalink to this definition"></a></dt>
<dd><p>This property is DEPRECATED, use self.benchmark instead.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.ScenarioStream.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#avalanche.benchmarks.scenarios.TScenarioStream" title="avalanche.benchmarks.scenarios.TScenarioStream"><span class="pre">TScenarioStream</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">experience_idx</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">slice</span><span class="p"><span class="pre">,</span> </span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#avalanche.benchmarks.scenarios.TExperience" title="avalanche.benchmarks.scenarios.TExperience"><span class="pre">TExperience</span></a><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#avalanche.benchmarks.scenarios.TScenarioStream" title="avalanche.benchmarks.scenarios.TScenarioStream"><span class="pre">TScenarioStream</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_definitions/#ScenarioStream.__getitem__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.ScenarioStream.__getitem__" title="Permalink to this definition"></a></dt>
<dd><p>Gets an experience given its experience index (or a stream slice given
the experience order).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>experience_idx</strong> – An int describing the experience index or an
iterable/slice object describing a slice of this stream.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The Experience instance associated to the given experience
index or a sliced stream instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.ScenarioStream.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_definitions/#ScenarioStream.__len__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.ScenarioStream.__len__" title="Permalink to this definition"></a></dt>
<dd><p>Used to get the length of this stream (the amount of experiences).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The amount of experiences in this stream.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py data">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.TScenarioStream">
<span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">TScenarioStream</span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.TScenarioStream" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.StreamUserDef">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">StreamUserDef</span></span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#StreamUserDef"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.StreamUserDef" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">typing.NamedTuple</span></code></p>
<p>Typed version of namedtuple.</p>
<p>Usage in Python versions &gt;= 3.6:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Employee</span><span class="p">(</span><span class="n">NamedTuple</span><span class="p">):</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="nb">id</span><span class="p">:</span> <span class="nb">int</span>
</pre></div>
</div>
<p>This is equivalent to:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Employee</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;Employee&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;id&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>The resulting class has an extra __annotations__ attribute, giving a
dict that maps field names to types.  (The field names are also in
the _fields attribute, which is part of the namedtuple API.)
Alternative equivalent keyword syntax is also accepted:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Employee</span> <span class="o">=</span> <span class="n">NamedTuple</span><span class="p">(</span><span class="s1">&#39;Employee&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
</pre></div>
</div>
<p>In Python versions &lt;= 3.5 use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Employee</span> <span class="o">=</span> <span class="n">NamedTuple</span><span class="p">(</span><span class="s1">&#39;Employee&#39;</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)])</span>
</pre></div>
</div>
<p>Create and return a new object.  See help(type) for accurate signature.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.StreamUserDef.exps_data">
<span class="sig-name descname"><span class="pre">exps_data</span></span><em class="property"> <span class="pre">:TStreamDataOrigin</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.StreamUserDef.exps_data" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.StreamUserDef.exps_task_labels">
<span class="sig-name descname"><span class="pre">exps_task_labels</span></span><em class="property"> <span class="pre">:TStreamTaskLabels</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.StreamUserDef.exps_task_labels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.StreamUserDef.origin_dataset">
<span class="sig-name descname"><span class="pre">origin_dataset</span></span><em class="property"> <span class="pre">:TOriginDataset</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.StreamUserDef.origin_dataset" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.StreamUserDef.is_lazy">
<span class="sig-name descname"><span class="pre">is_lazy</span></span><em class="property"> <span class="pre">:Optional[bool]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.StreamUserDef.is_lazy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py data">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.TStreamUserDef">
<span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">TStreamUserDef</span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.TStreamUserDef" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py data">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.TStreamsUserDict">
<span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">TStreamsUserDict</span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.TStreamsUserDict" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.StreamDef">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">StreamDef</span></span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#StreamDef"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.StreamDef" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">typing.NamedTuple</span></code></p>
<p>Typed version of namedtuple.</p>
<p>Usage in Python versions &gt;= 3.6:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Employee</span><span class="p">(</span><span class="n">NamedTuple</span><span class="p">):</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="nb">id</span><span class="p">:</span> <span class="nb">int</span>
</pre></div>
</div>
<p>This is equivalent to:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Employee</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;Employee&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;id&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>The resulting class has an extra __annotations__ attribute, giving a
dict that maps field names to types.  (The field names are also in
the _fields attribute, which is part of the namedtuple API.)
Alternative equivalent keyword syntax is also accepted:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Employee</span> <span class="o">=</span> <span class="n">NamedTuple</span><span class="p">(</span><span class="s1">&#39;Employee&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
</pre></div>
</div>
<p>In Python versions &lt;= 3.5 use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Employee</span> <span class="o">=</span> <span class="n">NamedTuple</span><span class="p">(</span><span class="s1">&#39;Employee&#39;</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)])</span>
</pre></div>
</div>
<p>Create and return a new object.  See help(type) for accurate signature.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.StreamDef.exps_data">
<span class="sig-name descname"><span class="pre">exps_data</span></span><em class="property"> <span class="pre">:LazyDatasetSequence</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.StreamDef.exps_data" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.StreamDef.exps_task_labels">
<span class="sig-name descname"><span class="pre">exps_task_labels</span></span><em class="property"> <span class="pre">:Sequence[Set[int]]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.StreamDef.exps_task_labels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.StreamDef.origin_dataset">
<span class="sig-name descname"><span class="pre">origin_dataset</span></span><em class="property"> <span class="pre">:TOriginDataset</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.StreamDef.origin_dataset" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.StreamDef.is_lazy">
<span class="sig-name descname"><span class="pre">is_lazy</span></span><em class="property"> <span class="pre">:bool</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.StreamDef.is_lazy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py data">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.TStreamsDict">
<span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">TStreamsDict</span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.TStreamsDict" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py data">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.TGenericCLScenario">
<span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">TGenericCLScenario</span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.TGenericCLScenario" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericCLScenario">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">GenericCLScenario</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">:</span> <span class="pre">TGenericCLScenario,</span> <span class="pre">*,</span> <span class="pre">stream_definitions:</span> <span class="pre">TStreamsUserDict,</span> <span class="pre">complete_test_set_only:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False,</span> <span class="pre">experience_factory:</span> <span class="pre">Callable[['GenericScenarioStream',</span> <span class="pre">int],</span> <span class="pre">TExperience]</span> <span class="pre">=</span> <span class="pre">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#GenericCLScenario"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericCLScenario" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Generic[TExperience]</span></code></p>
<p>Base implementation of a Continual Learning benchmark instance.
A Continual Learning benchmark instance is defined by a set of streams of
experiences (batches or tasks depending on the terminology). Each experience
contains the training (or test, or validation, …) data that becomes
available at a certain time instant.</p>
<p>Experiences are usually defined in children classes, with this class serving
as the more general implementation. This class handles the most simple type
of assignment: each stream is defined as a list of experiences, each
experience is defined by a dataset.</p>
<p>Defining the “train” and “test” streams is mandatory. This class supports
custom streams as well. Custom streams can be accessed by using the
<cite>streamname_stream</cite> field of the created instance.</p>
<p>The name of custom streams can only contain letters, numbers or the “_”
character and must not start with a number.</p>
<p>Creates an instance of a Continual Learning benchmark instance.</p>
<p>The benchmark instance is defined by a stream definition dictionary,
which describes the content of each stream. The “train” and “test”
stream are mandatory. Any other custom stream can be added.</p>
<p>There is no constraint on the amount of experiences in each stream
(excluding the case in which <cite>complete_test_set_only</cite> is set).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>stream_definitions</strong> – The stream definitions dictionary. Must
be a dictionary where the key is the stream name and the value
is the definition of that stream. “train” and “test” streams are
mandatory. This class supports custom streams as well. The name of
custom streams can only contain letters, numbers and the “_”
character and must not start with a number. Streams can be defined
is two ways: static and lazy. In the static case, the
stream must be a tuple containing 1, 2 or 3 elements:
- The first element must be a list containing the datasets
describing each experience. Datasets must be instances of
<code class="xref py py-class docutils literal notranslate"><span class="pre">AvalancheDataset</span></code>.
- The second element is optional and must be a list containing the
task labels of each experience (as an int or a set of ints).
If the stream definition tuple contains only one element (the list
of datasets), then the task labels for each experience will be
obtained by inspecting the content of the datasets.
- The third element is optional and must be a reference to the
originating dataset (if applicable). For instance, for SplitMNIST
this may be a reference to the whole MNIST dataset. If the stream
definition tuple contains less than 3 elements, then the reference
to the original dataset will be set to None.
In the lazy case, the stream must be defined as a tuple with 2
elements:
- The first element must be a tuple containing the dataset generator
(one for each experience) and the number of experiences in that
stream.
- The second element must be a list containing the task labels of
each experience (as an int or a set of ints).</p></li>
<li><p><strong>complete_test_set_only</strong> – If True, the test stream will contain
a single experience containing the complete test set. This also
means that the definition for the test stream must contain the
definition for a single experience.</p></li>
<li><p><strong>experience_factory</strong> – If not None, a callable that, given the
benchmark instance and the experience ID, returns a experience
instance. This parameter is usually used in subclasses (when
invoking the super constructor) to specialize the experience class.
Defaults to None, which means that the <a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericExperience" title="avalanche.benchmarks.scenarios.GenericExperience"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericExperience</span></code></a>
constructor will be used.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericCLScenario.stream_definitions">
<span class="sig-name descname"><span class="pre">stream_definitions</span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericCLScenario.stream_definitions" title="Permalink to this definition"></a></dt>
<dd><p>A structure containing the definition of the streams.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericCLScenario.original_train_dataset">
<span class="sig-name descname"><span class="pre">original_train_dataset</span></span><em class="property"> <span class="pre">:Optional[Dataset]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericCLScenario.original_train_dataset" title="Permalink to this definition"></a></dt>
<dd><p>The original training set. May be None.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericCLScenario.original_test_dataset">
<span class="sig-name descname"><span class="pre">original_test_dataset</span></span><em class="property"> <span class="pre">:Optional[Dataset]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericCLScenario.original_test_dataset" title="Permalink to this definition"></a></dt>
<dd><p>The original test set. May be None.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericCLScenario.train_stream">
<span class="sig-name descname"><span class="pre">train_stream</span></span><em class="property"> <span class="pre">:GenericScenarioStream[TExperience,</span> <span class="pre">TGenericCLScenario]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericCLScenario.train_stream" title="Permalink to this definition"></a></dt>
<dd><p>The stream used to obtain the training experiences.
This stream can be sliced in order to obtain a subset of this stream.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericCLScenario.test_stream">
<span class="sig-name descname"><span class="pre">test_stream</span></span><em class="property"> <span class="pre">:GenericScenarioStream[TExperience,</span> <span class="pre">TGenericCLScenario]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericCLScenario.test_stream" title="Permalink to this definition"></a></dt>
<dd><p>The stream used to obtain the test experiences. This stream can be
sliced in order to obtain a subset of this stream.</p>
<p>Beware that, in certain scenarios, this stream may contain a single
element. Check the <code class="docutils literal notranslate"><span class="pre">complete_test_set_only</span></code> field for more details.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericCLScenario.complete_test_set_only">
<span class="sig-name descname"><span class="pre">complete_test_set_only</span></span><em class="property"> <span class="pre">:bool</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericCLScenario.complete_test_set_only" title="Permalink to this definition"></a></dt>
<dd><p>If True, only the complete test set will be returned from experience
instances.</p>
<p>This flag is usually set to True in scenarios where having one separate
test set aligned to each training experience is impossible or doesn’t
make sense from a semantic point of view.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericCLScenario.streams">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">streams</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">'GenericScenarioStream[TExperience,</span> <span class="pre">TGenericCLScenario]'</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericCLScenario.streams" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericCLScenario.n_experiences">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">n_experiences</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericCLScenario.n_experiences" title="Permalink to this definition"></a></dt>
<dd><p>The number of incremental training experiences contained
in the train stream.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericCLScenario.task_labels">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">task_labels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericCLScenario.task_labels" title="Permalink to this definition"></a></dt>
<dd><p>The task label of each training experience.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericCLScenario.get_reproducibility_data">
<span class="sig-name descname"><span class="pre">get_reproducibility_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#GenericCLScenario.get_reproducibility_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericCLScenario.get_reproducibility_data" title="Permalink to this definition"></a></dt>
<dd><p>Gets the data needed to reproduce this experiment.</p>
<p>This data can be stored using the pickle module or some other mechanism.
It can then be loaded by passing it as the <code class="docutils literal notranslate"><span class="pre">reproducibility_data</span></code>
parameter in the constructor.</p>
<p>Child classes should create their own reproducibility dictionary.
This means that the implementation found in <a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericCLScenario" title="avalanche.benchmarks.scenarios.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a>
will return an empty dictionary, which is meaningless.</p>
<p>In order to obtain the same benchmark instance, the reproducibility
data must be passed to the constructor along with the exact same
input datasets.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A dictionary containing the data needed to reproduce the
experiment.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericCLScenario.classes_in_experience">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">classes_in_experience</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Set</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericCLScenario.classes_in_experience" title="Permalink to this definition"></a></dt>
<dd><p>A dictionary mapping each stream (by name) to a list.</p>
<p>Each element of the list is a set describing the classes included in
that experience (identified by its index).</p>
<p>In previous releases this field contained the list of sets for the
training stream (that is, there was no way to obtain the list for other
streams). That behavior is deprecated and support for that usage way
will be removed in the future.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericCLScenario.get_classes_timeline">
<span class="sig-name descname"><span class="pre">get_classes_timeline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_experience</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'train'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#GenericCLScenario.get_classes_timeline"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericCLScenario.get_classes_timeline" title="Permalink to this definition"></a></dt>
<dd><p>Returns the classes timeline given the ID of a experience.</p>
<p>Given a experience ID, this method returns the classes in that
experience, previously seen classes, the cumulative class list and a
list of classes that will be encountered in next experiences of the
same stream.</p>
<p>Beware that by default this will obtain the timeline of an experience
of the <strong>training</strong> stream. Use the stream parameter to select another
stream.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>current_experience</strong> – The reference experience ID.</p></li>
<li><p><strong>stream</strong> – The stream name.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tuple composed of four lists: the first list contains the
IDs of classes in this experience, the second contains IDs of
classes seen in previous experiences, the third returns a cumulative
list of classes (that is, the union of the first two list) while the
last one returns a list of classes that will be encountered in next
experiences. Beware that each of these elements can be None when
the benchmark is initialized by using a lazy generator.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericScenarioStream">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">GenericScenarioStream</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">:</span> <span class="pre">TGenericScenarioStream</span></em>, <em class="sig-param"><span class="pre">name:</span> <span class="pre">str</span></em>, <em class="sig-param"><span class="pre">benchmark:</span> <span class="pre">TGenericCLScenario</span></em>, <em class="sig-param"><span class="pre">*</span></em>, <em class="sig-param"><span class="pre">slice_ids:</span> <span class="pre">List[int]</span> <span class="pre">=</span> <span class="pre">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#GenericScenarioStream"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericScenarioStream" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Generic[TExperience,</span> <span class="pre">TGenericCLScenario]</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ScenarioStream[TGenericCLScenario,</span> <span class="pre">TExperience]</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence[TExperience]</span></code></p>
<p>A scenario stream describes a sequence of incremental experiences.
Experiences are described as <code class="xref py py-class docutils literal notranslate"><span class="pre">IExperience</span></code> instances. They contain a
set of patterns which has become available at a particular time instant
along with any optional, scenario specific, metadata.</p>
<p>Most scenario expose two different streams: the training stream and the test
stream.</p>
<p>Initialize self.  See help(type(self)) for accurate signature.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericScenarioStream.slice_ids">
<span class="sig-name descname"><span class="pre">slice_ids</span></span><em class="property"> <span class="pre">:Optional[List[int]]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericScenarioStream.slice_ids" title="Permalink to this definition"></a></dt>
<dd><p>Describes which experiences are contained in the current stream slice.
Can be None, which means that this object is the original stream.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericScenarioStream.name">
<span class="sig-name descname"><span class="pre">name</span></span><em class="property"> <span class="pre">:str</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericScenarioStream.name" title="Permalink to this definition"></a></dt>
<dd><p>The name of the stream (for instance: “train”, “test”, “valid”, …).</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericScenarioStream.benchmark">
<span class="sig-name descname"><span class="pre">benchmark</span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericScenarioStream.benchmark" title="Permalink to this definition"></a></dt>
<dd><p>A reference to the benchmark.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericScenarioStream.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#GenericScenarioStream.__len__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericScenarioStream.__len__" title="Permalink to this definition"></a></dt>
<dd><p>Gets the number of experiences this stream it’s made of.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The number of experiences in this stream.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericScenarioStream.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_idx</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">slice</span><span class="p"><span class="pre">,</span> </span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#avalanche.benchmarks.scenarios.TExperience" title="avalanche.benchmarks.scenarios.TExperience"><span class="pre">TExperience</span></a><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#avalanche.benchmarks.scenarios.TScenarioStream" title="avalanche.benchmarks.scenarios.TScenarioStream"><span class="pre">TScenarioStream</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#GenericScenarioStream.__getitem__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericScenarioStream.__getitem__" title="Permalink to this definition"></a></dt>
<dd><p>Gets a experience given its experience index (or a stream slice given
the experience order).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>exp_idx</strong> – An int describing the experience index or an
iterable/slice object describing a slice of this stream.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The experience instance associated to the given experience
index or a sliced stream instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericScenarioStream.drop_previous_experiences">
<span class="sig-name descname"><span class="pre">drop_previous_experiences</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_exp</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#GenericScenarioStream.drop_previous_experiences"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericScenarioStream.drop_previous_experiences" title="Permalink to this definition"></a></dt>
<dd><p>Drop the reference to experiences up to a certain experience ID
(inclusive).</p>
<p>This means that any reference to experiences with ID [0, from_exp] will
be released. By dropping the reference to previous experiences, the
memory associated with them can be freed, especially the one occupied by
the dataset. However, if external references to the experience or the
dataset still exist, dropping previous experiences at the stream level
will have little to no impact on the memory usage.</p>
<p>To make sure that the underlying dataset can be freed, make sure that:
- No reference to previous datasets or experiences are kept in you code;
- The replay implementation doesn’t keep a reference to previous</p>
<blockquote>
<div><p>datasets (in which case, is better to store a copy of the raw
tensors instead);</p>
</div></blockquote>
<ul class="simple">
<li><p>The benchmark is being generated using a lazy initializer.</p></li>
</ul>
<p>By dropping previous experiences, those experiences will no longer be
available in the stream. Trying to access them will result in an
exception.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>to_exp</strong> – The ID of the last exp to drop (inclusive). Can be a
negative number, in which case this method doesn’t have any effect.
Can be greater or equal to the stream length, in which case all
currently loaded experiences will be dropped.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.AbstractExperience">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">AbstractExperience</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">:</span> <span class="pre">TExperience,</span> <span class="pre">origin_stream:</span> <span class="pre">TScenarioStream,</span> <span class="pre">current_experience:</span> <span class="pre">int,</span> <span class="pre">classes_in_this_exp:</span> <span class="pre">Sequence[int],</span> <span class="pre">previous_classes:</span> <span class="pre">Sequence[int],</span> <span class="pre">classes_seen_so_far:</span> <span class="pre">Sequence[int],</span> <span class="pre">future_classes:</span> <span class="pre">Optional[Sequence[int]]</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#AbstractExperience"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.AbstractExperience" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Experience[TScenario,</span> <span class="pre">TScenarioStream]</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Definition of a learning experience. A learning experience contains a set of
patterns which has become available at a particular time instant. The
content and size of an Experience is defined by the specific benchmark that
creates the experience.</p>
<p>For instance, an experience of a New Classes scenario will contain all
patterns belonging to a subset of classes of the original training set. An
experience of a New Instance scenario will contain patterns from previously
seen classes.</p>
<p>Creates an instance of the abstract experience given the benchmark
stream, the current experience ID and data about the classes timeline.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>origin_stream</strong> – The stream from which this experience was
obtained.</p></li>
<li><p><strong>current_experience</strong> – The current experience ID, as an integer.</p></li>
<li><p><strong>classes_in_this_exp</strong> – The list of classes in this experience.</p></li>
<li><p><strong>previous_classes</strong> – The list of classes in previous experiences.</p></li>
<li><p><strong>classes_seen_so_far</strong> – List of classes of current and previous
experiences.</p></li>
<li><p><strong>future_classes</strong> – The list of classes of next experiences.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.AbstractExperience.classes_in_this_experience">
<span class="sig-name descname"><span class="pre">classes_in_this_experience</span></span><em class="property"> <span class="pre">:Sequence[int]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.AbstractExperience.classes_in_this_experience" title="Permalink to this definition"></a></dt>
<dd><p>The list of classes in this experience</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.AbstractExperience.previous_classes">
<span class="sig-name descname"><span class="pre">previous_classes</span></span><em class="property"> <span class="pre">:Sequence[int]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.AbstractExperience.previous_classes" title="Permalink to this definition"></a></dt>
<dd><p>The list of classes in previous experiences</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.AbstractExperience.classes_seen_so_far">
<span class="sig-name descname"><span class="pre">classes_seen_so_far</span></span><em class="property"> <span class="pre">:Sequence[int]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.AbstractExperience.classes_seen_so_far" title="Permalink to this definition"></a></dt>
<dd><p>List of classes of current and previous experiences</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.AbstractExperience.future_classes">
<span class="sig-name descname"><span class="pre">future_classes</span></span><em class="property"> <span class="pre">:Optional[Sequence[int]]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.AbstractExperience.future_classes" title="Permalink to this definition"></a></dt>
<dd><p>The list of classes of next experiences</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.AbstractExperience.task_label">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">task_label</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.AbstractExperience.task_label" title="Permalink to this definition"></a></dt>
<dd><p>The task label. This value will never have value “None”. However,
for scenarios that don’t produce task labels a placeholder value like 0
is usually set. Beware that this field is meant as a shortcut to obtain
a unique task label: it assumes that only patterns labeled with a
single task label are present. If this experience contains patterns from
multiple tasks, accessing this property will result in an exception.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericExperience">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">GenericExperience</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">:</span> <span class="pre">TGenericExperience,</span> <span class="pre">origin_stream:</span> <span class="pre">GenericScenarioStream[TGenericExperience,</span> <span class="pre">TGenericCLScenario],</span> <span class="pre">current_experience:</span> <span class="pre">int</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#GenericExperience"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericExperience" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractExperience[TGenericCLScenario,</span> <span class="pre">GenericScenarioStream[TGenericExperience,</span> <span class="pre">TGenericCLScenario]]</span></code></p>
<p>Definition of a learning experience based on a <a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericCLScenario" title="avalanche.benchmarks.scenarios.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a>
instance.</p>
<p>This experience implementation uses the generic experience-patterns
assignment defined in the <a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericCLScenario" title="avalanche.benchmarks.scenarios.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a> instance. Instances of
this class are usually obtained from a benchmark stream.</p>
<p>Creates an instance of a generic experience given the stream from this
experience was taken and and the current experience ID.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>origin_stream</strong> – The stream from which this experience was
obtained.</p></li>
<li><p><strong>current_experience</strong> – The current experience ID, as an integer.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.GenericExperience.task_labels">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">task_labels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.GenericExperience.task_labels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.create_multi_dataset_generic_scenario">
<span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">create_multi_dataset_generic_scenario</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataset_list</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">SupportedDataset</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataset_list</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">SupportedDataset</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">complete_test_set_only</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_type</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">AvalancheDatasetType</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericCLScenario" title="avalanche.benchmarks.scenarios.GenericCLScenario"><span class="pre">GenericCLScenario</span></a></span></span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_scenario_creation/#create_multi_dataset_generic_scenario"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.create_multi_dataset_generic_scenario" title="Permalink to this definition"></a></dt>
<dd><p>This helper function is DEPRECATED in favor of
<cite>create_multi_dataset_generic_benchmark</cite>.</p>
<p>Creates a generic scenario given a list of datasets and the respective task
labels. Each training dataset will be considered as a separate training
experience. Contents of the datasets will not be changed, including the
targets.</p>
<p>When loading the datasets from a set of fixed filelist, consider using
the <a class="reference internal" href="#avalanche.benchmarks.scenarios.create_generic_scenario_from_filelists" title="avalanche.benchmarks.scenarios.create_generic_scenario_from_filelists"><code class="xref py py-func docutils literal notranslate"><span class="pre">create_generic_scenario_from_filelists()</span></code></a> helper method instead.</p>
<p>In its base form, this function accepts a list of test datsets that must
contain the same amount of datasets of the training list.
Those pairs are then used to create the “past”, “cumulative”
(a.k.a. growing) and “future” test sets. However, in certain Continual
Learning scenarios only the concept of “complete” test set makes sense. In
that case, the <code class="docutils literal notranslate"><span class="pre">complete_test_set_only</span></code> should be set to True (see the
parameter description for more info).</p>
<p>Beware that pattern transformations must already be included in the
datasets (when needed).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset_list</strong> – A list of training datasets.</p></li>
<li><p><strong>test_dataset_list</strong> – A list of test datasets.</p></li>
<li><p><strong>task_labels</strong> – A list of task labels. Must contain the same amount of
elements of the <code class="docutils literal notranslate"><span class="pre">train_dataset_list</span></code> parameter. For
Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
a list of zeros. For Multi Task scenario, this is usually a list of
ascending task labels (starting from 0).</p></li>
<li><p><strong>complete_test_set_only</strong> – If True, only the complete test set will
be returned by the scenario. This means that the <code class="docutils literal notranslate"><span class="pre">test_dataset_list</span></code>
parameter must be list with a single element (the complete test set).
Defaults to False, which means that <code class="docutils literal notranslate"><span class="pre">train_dataset_list</span></code> and
<code class="docutils literal notranslate"><span class="pre">test_dataset_list</span></code> must contain the same amount of datasets.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>train_target_transform</strong> – The transformation to apply to training
patterns targets. Defaults to None.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>eval_target_transform</strong> – The transformation to apply to test
patterns targets. Defaults to None.</p></li>
<li><p><strong>dataset_type</strong> – The type of the dataset. Defaults to None, which
means that the type will be obtained from the input datasets. If input
datasets are not instances of <code class="xref py py-class docutils literal notranslate"><span class="pre">AvalancheDataset</span></code>, the type
UNDEFINED will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericCLScenario" title="avalanche.benchmarks.scenarios.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.create_generic_scenario_from_filelists">
<span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">create_generic_scenario_from_filelists</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Path</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_file_lists</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Path</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_file_lists</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Path</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Path</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">complete_test_set_only</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericCLScenario" title="avalanche.benchmarks.scenarios.GenericCLScenario"><span class="pre">GenericCLScenario</span></a></span></span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_scenario_creation/#create_generic_scenario_from_filelists"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.create_generic_scenario_from_filelists" title="Permalink to this definition"></a></dt>
<dd><p>This helper function is DEPRECATED in favor of
<cite>create_generic_benchmark_from_filelists</cite>.</p>
<p>Creates a generic scenario given a list of filelists and the respective task
labels. A separate dataset will be created for each filelist and each of
those training datasets will be considered a separate training experience.</p>
<p>In its base form, this function accepts a list of filelists for the test
datsets that must contain the same amount of elements of the training list.
Those pairs of datasets are then used to create the “past”, “cumulative”
(a.k.a. growing) and “future” test sets. However, in certain Continual
Learning scenarios only the concept of “complete” test set makes sense. In
that case, the <code class="docutils literal notranslate"><span class="pre">complete_test_set_only</span></code> should be set to True (see the
parameter description for more info).</p>
<p>This helper functions is the best shot when loading Caffe-style dataset
based on filelists.</p>
<p>The resulting benchmark instance and the intermediate datasets used to
populate it will be of type CLASSIFICATION.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> – The root path of the dataset.</p></li>
<li><p><strong>train_file_lists</strong> – A list of filelists describing the
paths of the training patterns for each experience.</p></li>
<li><p><strong>test_file_lists</strong> – A list of filelists describing the
paths of the test patterns for each experience.</p></li>
<li><p><strong>task_labels</strong> – A list of task labels. Must contain the same amount of
elements of the <code class="docutils literal notranslate"><span class="pre">train_file_lists</span></code> parameter. For
Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
a list of zeros. For Multi Task scenario, this is usually a list of
ascending task labels (starting from 0).</p></li>
<li><p><strong>complete_test_set_only</strong> – If True, only the complete test set will
be returned by the scenario. This means that the <code class="docutils literal notranslate"><span class="pre">test_file_lists</span></code>
parameter must be list with a single element (the complete test set).
Alternatively, can be a plain string or <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code> object.
Defaults to False, which means that <code class="docutils literal notranslate"><span class="pre">train_file_lists</span></code> and
<code class="docutils literal notranslate"><span class="pre">test_file_lists</span></code> must contain the same amount of filelists paths.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>train_target_transform</strong> – The transformation to apply to training
patterns targets. Defaults to None.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>eval_target_transform</strong> – The transformation to apply to test
patterns targets. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericCLScenario" title="avalanche.benchmarks.scenarios.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.create_generic_scenario_from_paths">
<span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">create_generic_scenario_from_paths</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_list_of_files</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">FileAndLabel</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_list_of_files</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">FileAndLabel</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">FileAndLabel</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">complete_test_set_only</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_type</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">AvalancheDatasetType</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">AvalancheDatasetType.UNDEFINED</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericCLScenario" title="avalanche.benchmarks.scenarios.GenericCLScenario"><span class="pre">GenericCLScenario</span></a></span></span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_scenario_creation/#create_generic_scenario_from_paths"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.create_generic_scenario_from_paths" title="Permalink to this definition"></a></dt>
<dd><p>This helper function is DEPRECATED in favor of
<cite>create_generic_benchmark_from_paths</cite>.</p>
<p>Creates a generic scenario given a sequence of lists of files. A separate
dataset will be created for each list. Each of those training datasets
will be considered a separate training experience.</p>
<p>This is very similar to <cite>create_generic_scenario_from_filelists</cite>, with the
main difference being that <cite>create_generic_scenario_from_filelists</cite>
accepts, for each experience, a file list formatted in Caffe-style.
On the contrary, this accepts a list of tuples where each tuple contains
two elements: the full path to the pattern and its label.
Optionally, the tuple may contain a third element describing the bounding
box of the element to crop. This last bounding box may be useful when trying
to extract the part of the image depicting the desired element.</p>
<p>In its base form, this function accepts a list for the test datasets that
must contain the same amount of elements of the training list.
Those pairs of datasets are then used to create the “past”, “cumulative”
(a.k.a. growing) and “future” test sets. However, in certain Continual
Learning scenarios only the concept of “complete” test set makes sense. In
that case, the <code class="docutils literal notranslate"><span class="pre">complete_test_set_only</span></code> should be set to True (see the
parameter description for more info).</p>
<p>The label of each pattern doesn’t have to be an int.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_list_of_files</strong> – A list of lists. Each list describes the paths
and labels of patterns to include in that training experience, as
tuples. Each tuple must contain two elements: the full path to the
pattern and its class label. Optionally, the tuple may contain a
third element describing the bounding box to use for cropping (top,
left, height, width).</p></li>
<li><p><strong>test_list_of_files</strong> – A list of lists. Each list describes the paths
and labels of patterns to include in that test experience, as tuples.
Each tuple must contain two elements: the full path to the pattern
and its class label. Optionally, the tuple may contain a third element
describing the bounding box to use for cropping (top, left, height,
width).</p></li>
<li><p><strong>task_labels</strong> – A list of task labels. Must contain the same amount of
elements of the <code class="docutils literal notranslate"><span class="pre">train_file_lists</span></code> parameter. For
Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
a list of zeros. For Multi Task scenario, this is usually a list of
ascending task labels (starting from 0).</p></li>
<li><p><strong>complete_test_set_only</strong> – If True, only the complete test set will
be returned by the scenario. This means that the <code class="docutils literal notranslate"><span class="pre">test_list_of_files</span></code>
parameter must define a single experience (the complete test set).
Defaults to False, which means that <code class="docutils literal notranslate"><span class="pre">train_list_of_files</span></code> and
<code class="docutils literal notranslate"><span class="pre">test_list_of_files</span></code> must contain the same amount of paths.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>train_target_transform</strong> – The transformation to apply to training
patterns targets. Defaults to None.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>eval_target_transform</strong> – The transformation to apply to test
patterns targets. Defaults to None.</p></li>
<li><p><strong>dataset_type</strong> – The type of the dataset. Defaults to UNDEFINED.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericCLScenario" title="avalanche.benchmarks.scenarios.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.create_generic_scenario_from_tensor_lists">
<span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">create_generic_scenario_from_tensor_lists</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_tensors</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_tensors</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">complete_test_set_only</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_type</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">AvalancheDatasetType</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericCLScenario" title="avalanche.benchmarks.scenarios.GenericCLScenario"><span class="pre">GenericCLScenario</span></a></span></span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_scenario_creation/#create_generic_scenario_from_tensor_lists"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.create_generic_scenario_from_tensor_lists" title="Permalink to this definition"></a></dt>
<dd><p>This helper function is DEPRECATED in favor of
<cite>create_generic_benchmark_from_tensor_lists</cite>.</p>
<p>Creates a generic scenario given lists of Tensors. A separate dataset will
be created from each Tensor tuple (x, y, z, …) and each of those training
datasets will be considered a separate training experience. Using this
helper function is the lowest-level way to create a Continual Learning
scenario. When possible, consider using higher level helpers.</p>
<p>Experiences are defined by passing lists of tensors as the <cite>train_tensors</cite>
and <cite>test_tensors</cite> parameter. Those parameters must be lists containing
sub-lists of tensors, one for each experience. Each tensor defines the value
of a feature (“x”, “y”, “z”, …) for all patterns of that experience.</p>
<p>By default the second tensor of each experience will be used to fill the
<cite>targets</cite> value (label of each pattern).</p>
<p>In its base form, the test lists must contain the same amount of elements of
the training lists. Those pairs of datasets are then used to create the
“past”, “cumulative” (a.k.a. growing) and “future” test sets.
However, in certain Continual Learning scenarios only the concept of
“complete” test set makes sense. In that case, the
<code class="docutils literal notranslate"><span class="pre">complete_test_set_only</span></code> should be set to True (see the parameter
description for more info).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_tensors</strong> – A list of lists. The first list must contain the
tensors for the first training experience (one tensor per feature), the
second list must contain the tensors for the second training experience,
and so on.</p></li>
<li><p><strong>test_tensors</strong> – A list of lists. The first list must contain the
tensors for the first test experience (one tensor per feature), the
second list must contain the tensors for the second test experience,
and so on. When using <cite>complete_test_set_only</cite>, this parameter
must be a list containing a single sub-list for the single test
experience.</p></li>
<li><p><strong>task_labels</strong> – A list of task labels. Must contain a task label for
each experience. For Single-Incremental-Task (a.k.a. Task-Free)
scenarios, this is usually a list of zeros. For Multi Task scenario,
this is usually a list of ascending task labels (starting from 0).</p></li>
<li><p><strong>complete_test_set_only</strong> – If True, only the complete test set will
be returned by the scenario. This means that <code class="docutils literal notranslate"><span class="pre">test_tensors</span></code> must
define a single experience. Defaults to False, which means that
<code class="docutils literal notranslate"><span class="pre">train_tensors</span></code> and <code class="docutils literal notranslate"><span class="pre">test_tensors</span></code> must define the same
amount of experiences.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>train_target_transform</strong> – The transformation to apply to training
patterns targets. Defaults to None.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>eval_target_transform</strong> – The transformation to apply to test
patterns targets. Defaults to None.</p></li>
<li><p><strong>dataset_type</strong> – The type of the dataset. Defaults to None, which
means that the type will be obtained from the input datasets. If input
datasets are not instances of <code class="xref py py-class docutils literal notranslate"><span class="pre">AvalancheDataset</span></code>, the type
UNDEFINED will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericCLScenario" title="avalanche.benchmarks.scenarios.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.create_generic_scenario_from_tensors">
<span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">create_generic_scenario_from_tensors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_data_x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_data_y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">SupportsInt</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_data_x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_data_y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">SupportsInt</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">complete_test_set_only</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_type</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">AvalancheDatasetType</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">AvalancheDatasetType.UNDEFINED</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericCLScenario" title="avalanche.benchmarks.scenarios.GenericCLScenario"><span class="pre">GenericCLScenario</span></a></span></span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/generic_scenario_creation/#create_generic_scenario_from_tensors"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.create_generic_scenario_from_tensors" title="Permalink to this definition"></a></dt>
<dd><p>This helper function is DEPRECATED in favor of
<cite>create_generic_benchmark_from_tensor_lists</cite>.</p>
<p>Please consider using <a class="reference internal" href="#avalanche.benchmarks.scenarios.create_generic_scenario_from_tensor_lists" title="avalanche.benchmarks.scenarios.create_generic_scenario_from_tensor_lists"><code class="xref py py-func docutils literal notranslate"><span class="pre">create_generic_scenario_from_tensor_lists()</span></code></a>
instead. When switching to the new function, please keep in mind that the
format of the parameters is completely different!</p>
<p>Creates a generic scenario given lists of Tensors and the respective task
labels. A separate dataset will be created from each Tensor pair (x + y)
and each of those training datasets will be considered a separate
training experience. Contents of the datasets will not be changed, including
the targets. Using this helper function is the lower level way to create a
Continual Learning scenario. When possible, consider using higher level
helpers.</p>
<p>By default the second tensor of each experience will be used to fill the
<cite>targets</cite> value (label of each pattern).</p>
<p>In its base form, the test lists must contain the same amount of elements of
the training lists. Those pairs of datasets are then used to create the
“past”, “cumulative” (a.k.a. growing) and “future” test sets.
However, in certain Continual Learning scenarios only the concept of
“complete” test set makes sense. In that case, the
<code class="docutils literal notranslate"><span class="pre">complete_test_set_only</span></code> should be set to True (see the parameter
description for more info).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_data_x</strong> – A list of Tensors (one per experience) containing the
patterns of the training sets.</p></li>
<li><p><strong>train_data_y</strong> – A list of Tensors or int lists containing the
labels of the patterns of the training sets. Must contain the same
number of elements of <code class="docutils literal notranslate"><span class="pre">train_datasets_x</span></code>.</p></li>
<li><p><strong>test_data_x</strong> – A Tensor or a list of Tensors (one per experience)
containing the patterns of the test sets.</p></li>
<li><p><strong>test_data_y</strong> – A Tensor or a list of Tensors or int lists containing
the labels of the patterns of the test sets. Must contain the same
number of elements of <code class="docutils literal notranslate"><span class="pre">test_datasets_x</span></code>.</p></li>
<li><p><strong>task_labels</strong> – A list of task labels. Must contain the same amount of
elements of the <code class="docutils literal notranslate"><span class="pre">train_datasets_x</span></code> parameter. For
Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
a list of zeros. For Multi Task scenario, this is usually a list of
ascending task labels (starting from 0).</p></li>
<li><p><strong>complete_test_set_only</strong> – If True, only the complete test set will
be returned by the scenario. This means that <code class="docutils literal notranslate"><span class="pre">test_data_x</span></code> and
<code class="docutils literal notranslate"><span class="pre">test_data_y</span></code> must define a single experience. Defaults to False,
which means that <code class="docutils literal notranslate"><span class="pre">train_data_*</span></code> and <code class="docutils literal notranslate"><span class="pre">test_data_*</span></code> must define the
same amount of experiences.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>train_target_transform</strong> – The transformation to apply to training
patterns targets. Defaults to None.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>eval_target_transform</strong> – The transformation to apply to test
patterns targets. Defaults to None.</p></li>
<li><p><strong>dataset_type</strong> – The type of the dataset. Defaults to UNDEFINED.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericCLScenario" title="avalanche.benchmarks.scenarios.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NCScenario">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">NCScenario</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">AvalancheDataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">AvalancheDataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_class_order</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_experience_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_ids_from_zero_from_first_exp</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_ids_from_zero_in_each_exp</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reproducibility_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/new_classes/nc_scenario/#NCScenario"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.NCScenario" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario['NCExperience']</span></code></p>
<p>This class defines a “New Classes” scenario. Once created, an instance
of this class can be iterated in order to obtain the experience sequence
under the form of instances of <a class="reference internal" href="#avalanche.benchmarks.scenarios.NCExperience" title="avalanche.benchmarks.scenarios.NCExperience"><code class="xref py py-class docutils literal notranslate"><span class="pre">NCExperience</span></code></a>.</p>
<p>This class can be used directly. However, we recommend using facilities like
<a class="reference internal" href="../generators/#avalanche.benchmarks.generators.nc_benchmark" title="avalanche.benchmarks.generators.nc_benchmark"><code class="xref py py-func docutils literal notranslate"><span class="pre">avalanche.benchmarks.generators.nc_benchmark()</span></code></a>.</p>
<p>Creates a <code class="docutils literal notranslate"><span class="pre">NCGenericScenario</span></code> instance given the training and test
Datasets and the number of experiences.</p>
<p>By default, the number of classes will be automatically detected by
looking at the training Dataset <code class="docutils literal notranslate"><span class="pre">targets</span></code> field. Classes will be
uniformly distributed across <code class="docutils literal notranslate"><span class="pre">n_experiences</span></code> unless a
<code class="docutils literal notranslate"><span class="pre">per_experience_classes</span></code> argument is specified.</p>
<p>The number of classes must be divisible without remainder by the number
of experiences. This also applies when the <code class="docutils literal notranslate"><span class="pre">per_experience_classes</span></code>
argument is not None.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> – The training dataset. The dataset must be a
subclass of <code class="xref py py-class docutils literal notranslate"><span class="pre">AvalancheDataset</span></code>. For instance, one can
use the datasets from the torchvision package like that:
<code class="docutils literal notranslate"><span class="pre">train_dataset=AvalancheDataset(torchvision_dataset)</span></code>.</p></li>
<li><p><strong>test_dataset</strong> – The test dataset. The dataset must be a
subclass of <code class="xref py py-class docutils literal notranslate"><span class="pre">AvalancheDataset</span></code>. For instance, one can
use the datasets from the torchvision package like that:
<code class="docutils literal notranslate"><span class="pre">test_dataset=AvalancheDataset(torchvision_dataset)</span></code>.</p></li>
<li><p><strong>n_experiences</strong> – The number of experiences.</p></li>
<li><p><strong>task_labels</strong> – If True, each experience will have an ascending task
label. If False, the task label will be 0 for all the experiences.</p></li>
<li><p><strong>shuffle</strong> – If True, the class order will be shuffled. Defaults to
True.</p></li>
<li><p><strong>seed</strong> – If shuffle is True and seed is not None, the class order
will be shuffled according to the seed. When None, the current
PyTorch random number generator state will be used.
Defaults to None.</p></li>
<li><p><strong>fixed_class_order</strong> – If not None, the class order to use (overrides
the shuffle argument). Very useful for enhancing
reproducibility. Defaults to None.</p></li>
<li><p><strong>per_experience_classes</strong> – Is not None, a dictionary whose keys are
(0-indexed) experience IDs and their values are the number of
classes to include in the respective experiences. The dictionary
doesn’t have to contain a key for each experience! All the remaining
experiences will contain an equal amount of the remaining classes.
The remaining number of classes must be divisible without remainder
by the remaining number of experiences. For instance,
if you want to include 50 classes in the first experience
while equally distributing remaining classes across remaining
experiences, just pass the “{0: 50}” dictionary as the
per_experience_classes parameter. Defaults to None.</p></li>
<li><p><strong>class_ids_from_zero_from_first_exp</strong> – If True, original class IDs
will be remapped so that they will appear as having an ascending
order. For instance, if the resulting class order after shuffling
(or defined by fixed_class_order) is [23, 34, 11, 7, 6, …] and
class_ids_from_zero_from_first_exp is True, then all the patterns
belonging to class 23 will appear as belonging to class “0”,
class “34” will be mapped to “1”, class “11” to “2” and so on.
This is very useful when drawing confusion matrices and when dealing
with algorithms with dynamic head expansion. Defaults to False.
Mutually exclusive with the <code class="docutils literal notranslate"><span class="pre">class_ids_from_zero_in_each_exp</span></code>
parameter.</p></li>
<li><p><strong>class_ids_from_zero_in_each_exp</strong> – If True, original class IDs
will be mapped to range [0, n_classes_in_exp) for each experience.
Defaults to False. Mutually exclusive with the
<code class="docutils literal notranslate"><span class="pre">class_ids_from_zero_from_first_exp</span> <span class="pre">parameter</span></code>.</p></li>
<li><p><strong>reproducibility_data</strong> – If not None, overrides all the other
scenario definition options. This is usually a dictionary containing
data used to reproduce a specific experiment. One can use the
<code class="docutils literal notranslate"><span class="pre">get_reproducibility_data</span></code> method to get (and even distribute)
the experiment setup so that it can be loaded by passing it as this
parameter. In this way one can be sure that the same specific
experimental setup is being used (for reproducibility purposes).
Beware that, in order to reproduce an experiment, the same train and
test datasets must be used. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NCScenario.classes_order">
<span class="sig-name descname"><span class="pre">classes_order</span></span><em class="property"> <span class="pre">:List[int]</span> <span class="pre">=</span> <span class="pre">[]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.NCScenario.classes_order" title="Permalink to this definition"></a></dt>
<dd><p>Stores the class order (remapped class IDs).</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NCScenario.classes_order_original_ids">
<span class="sig-name descname"><span class="pre">classes_order_original_ids</span></span><em class="property"> <span class="pre">:List[int]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.NCScenario.classes_order_original_ids" title="Permalink to this definition"></a></dt>
<dd><p>Stores the class order (original class IDs)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NCScenario.class_mapping">
<span class="sig-name descname"><span class="pre">class_mapping</span></span><em class="property"> <span class="pre">:List[int]</span> <span class="pre">=</span> <span class="pre">[]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.NCScenario.class_mapping" title="Permalink to this definition"></a></dt>
<dd><p>class_mapping stores the class mapping so that
<cite>mapped_class_id = class_mapping[original_class_id]</cite>.</p>
<p>If the benchmark is created with an amount of classes which is less than
the amount of all classes in the dataset, then class_mapping will
contain some -1 values corresponding to ignored classes. This can
happen when passing a fixed class order to the constructor.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NCScenario.n_classes_per_exp">
<span class="sig-name descname"><span class="pre">n_classes_per_exp</span></span><em class="property"> <span class="pre">:List[int]</span> <span class="pre">=</span> <span class="pre">[]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.NCScenario.n_classes_per_exp" title="Permalink to this definition"></a></dt>
<dd><p>A list that, for each experience (identified by its index/ID),
stores the number of classes assigned to that experience.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NCScenario.original_classes_in_exp">
<span class="sig-name descname"><span class="pre">original_classes_in_exp</span></span><em class="property"> <span class="pre">:List[Set[int]]</span> <span class="pre">=</span> <span class="pre">[]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.NCScenario.original_classes_in_exp" title="Permalink to this definition"></a></dt>
<dd><p>A list that, for each experience (identified by its index/ID), stores a
set of the original IDs of classes assigned to that experience.
This field applies to both train and test streams.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NCScenario.class_ids_from_zero_from_first_exp">
<span class="sig-name descname"><span class="pre">class_ids_from_zero_from_first_exp</span></span><em class="property"> <span class="pre">:bool</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.NCScenario.class_ids_from_zero_from_first_exp" title="Permalink to this definition"></a></dt>
<dd><p>If True the class IDs have been remapped to start from zero.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NCScenario.class_ids_from_zero_in_each_exp">
<span class="sig-name descname"><span class="pre">class_ids_from_zero_in_each_exp</span></span><em class="property"> <span class="pre">:bool</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.NCScenario.class_ids_from_zero_in_each_exp" title="Permalink to this definition"></a></dt>
<dd><p>If True the class IDs have been remapped to start from zero in
each experience</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NCScenario.n_classes">
<span class="sig-name descname"><span class="pre">n_classes</span></span><em class="property"> <span class="pre">:int</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.NCScenario.n_classes" title="Permalink to this definition"></a></dt>
<dd><p>The number of classes</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NCScenario.train_exps_patterns_assignment">
<span class="sig-name descname"><span class="pre">train_exps_patterns_assignment</span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.NCScenario.train_exps_patterns_assignment" title="Permalink to this definition"></a></dt>
<dd><p>A list containing which training instances are assigned to each
experience in the train stream. Instances are identified by their id
w.r.t. the dataset found in the original_train_dataset field.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NCScenario.test_exps_patterns_assignment">
<span class="sig-name descname"><span class="pre">test_exps_patterns_assignment</span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.NCScenario.test_exps_patterns_assignment" title="Permalink to this definition"></a></dt>
<dd><p>A list containing which test instances are assigned to each
experience in the test stream. Instances are identified by their id
w.r.t. the dataset found in the original_test_dataset field.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NCScenario.get_reproducibility_data">
<span class="sig-name descname"><span class="pre">get_reproducibility_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/new_classes/nc_scenario/#NCScenario.get_reproducibility_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.NCScenario.get_reproducibility_data" title="Permalink to this definition"></a></dt>
<dd><p>Gets the data needed to reproduce this experiment.</p>
<p>This data can be stored using the pickle module or some other mechanism.
It can then be loaded by passing it as the <code class="docutils literal notranslate"><span class="pre">reproducibility_data</span></code>
parameter in the constructor.</p>
<p>Child classes should create their own reproducibility dictionary.
This means that the implementation found in <a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericCLScenario" title="avalanche.benchmarks.scenarios.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a>
will return an empty dictionary, which is meaningless.</p>
<p>In order to obtain the same benchmark instance, the reproducibility
data must be passed to the constructor along with the exact same
input datasets.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A dictionary containing the data needed to reproduce the
experiment.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NCScenario.classes_in_exp_range">
<span class="sig-name descname"><span class="pre">classes_in_exp_range</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_start</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_end</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/new_classes/nc_scenario/#NCScenario.classes_in_exp_range"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.NCScenario.classes_in_exp_range" title="Permalink to this definition"></a></dt>
<dd><p>Gets a list of classes contained in the given experiences. The
experiences are defined by range. This means that only the classes in
range [exp_start, exp_end) will be included.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>exp_start</strong> – The starting experience ID.</p></li>
<li><p><strong>exp_end</strong> – The final experience ID. Can be None, which means that
all the remaining experiences will be taken.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The classes contained in the required experience range.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NCExperience">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">NCExperience</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">origin_stream</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericScenarioStream" title="avalanche.benchmarks.scenarios.GenericScenarioStream"><span class="pre">GenericScenarioStream</span></a><span class="p"><span class="pre">[</span></span><span class="pre">'NCExperience'</span><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#avalanche.benchmarks.scenarios.NCScenario" title="avalanche.benchmarks.scenarios.NCScenario"><span class="pre">NCScenario</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_experience</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/new_classes/nc_scenario/#NCExperience"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.NCExperience" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">GenericExperience[NCScenario,</span> <span class="pre">GenericScenarioStream['NCExperience',</span> <span class="pre">NCScenario]]</span></code></p>
<p>Defines a “New Classes” experience. It defines fields to obtain the current
dataset and the associated task label. It also keeps a reference to the
stream from which this experience was taken.</p>
<p>Creates a <code class="docutils literal notranslate"><span class="pre">NCExperience</span></code> instance given the stream from this
experience was taken and and the current experience ID.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>origin_stream</strong> – The stream from which this experience was
obtained.</p></li>
<li><p><strong>current_experience</strong> – The current experience ID, as an integer.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NIScenario">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">NIScenario</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">AvalancheDataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">AvalancheDataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">balance_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_class_patterns_in_exp</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_exp_assignment</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reproducibility_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/new_instances/ni_scenario/#NIScenario"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.NIScenario" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario['NIExperience']</span></code></p>
<p>This class defines a “New Instance” scenario.
Once created, an instance of this class can be iterated in order to obtain
the experience sequence under the form of instances of
<a class="reference internal" href="#avalanche.benchmarks.scenarios.NIExperience" title="avalanche.benchmarks.scenarios.NIExperience"><code class="xref py py-class docutils literal notranslate"><span class="pre">NIExperience</span></code></a>.</p>
<p>Instances of this class can be created using the constructor directly.
However, we recommend using facilities like
<a class="reference internal" href="../generators/#avalanche.benchmarks.generators.ni_scenario" title="avalanche.benchmarks.generators.ni_scenario"><code class="xref py py-func docutils literal notranslate"><span class="pre">avalanche.benchmarks.generators.ni_scenario()</span></code></a>.</p>
<p>Consider that every method from <a class="reference internal" href="#avalanche.benchmarks.scenarios.NIExperience" title="avalanche.benchmarks.scenarios.NIExperience"><code class="xref py py-class docutils literal notranslate"><span class="pre">NIExperience</span></code></a> used to retrieve
parts of the test set (past, current, future, cumulative) always return the
complete test set. That is, they behave as the getter for the complete test
set.</p>
<p>Creates a NIScenario instance given the training and test Datasets and
the number of experiences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> – The training dataset. The dataset must be an
instance of <code class="xref py py-class docutils literal notranslate"><span class="pre">AvalancheDataset</span></code>. For instance, one can
use the datasets from the torchvision package like that:
<code class="docutils literal notranslate"><span class="pre">train_dataset=AvalancheDataset(torchvision_dataset)</span></code>.</p></li>
<li><p><strong>test_dataset</strong> – The test dataset. The dataset must be a
subclass of <code class="xref py py-class docutils literal notranslate"><span class="pre">AvalancheDataset</span></code>. For instance, one can
use the datasets from the torchvision package like that:
<code class="docutils literal notranslate"><span class="pre">test_dataset=AvalancheDataset(torchvision_dataset)</span></code>.</p></li>
<li><p><strong>n_experiences</strong> – The number of experiences.</p></li>
<li><p><strong>task_labels</strong> – If True, each experience will have an ascending task
label. If False, the task label will be 0 for all the experiences.
Defaults to False.</p></li>
<li><p><strong>shuffle</strong> – If True, the patterns order will be shuffled. Defaults
to True.</p></li>
<li><p><strong>seed</strong> – If shuffle is True and seed is not None, the class order
will be shuffled according to the seed. When None, the current
PyTorch random number generator state will be used.
Defaults to None.</p></li>
<li><p><strong>balance_experiences</strong> – If True, pattern of each class will be
equally spread across all experiences. If False, patterns will be
assigned to experiences in a complete random way. Defaults to False.</p></li>
<li><p><strong>min_class_patterns_in_exp</strong> – The minimum amount of patterns of
every class that must be assigned to every experience. Compatible
with the <code class="docutils literal notranslate"><span class="pre">balance_experiences</span></code> parameter. An exception will be
raised if this constraint can’t be satisfied. Defaults to 0.</p></li>
<li><p><strong>fixed_exp_assignment</strong> – If not None, the pattern assignment
to use. It must be a list with an entry for each experience. Each
entry is a list that contains the indexes of patterns belonging to
that experience. Overrides the <code class="docutils literal notranslate"><span class="pre">shuffle</span></code>, <code class="docutils literal notranslate"><span class="pre">balance_experiences</span></code>
and <code class="docutils literal notranslate"><span class="pre">min_class_patterns_in_exp</span></code> parameters.</p></li>
<li><p><strong>reproducibility_data</strong> – If not None, overrides all the other
scenario definition options, including <code class="docutils literal notranslate"><span class="pre">fixed_exp_assignment</span></code>.
This is usually a dictionary containing data used to
reproduce a specific experiment. One can use the
<code class="docutils literal notranslate"><span class="pre">get_reproducibility_data</span></code> method to get (and even distribute)
the experiment setup so that it can be loaded by passing it as this
parameter. In this way one can be sure that the same specific
experimental setup is being used (for reproducibility purposes).
Beware that, in order to reproduce an experiment, the same train and
test datasets must be used. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NIScenario.n_classes">
<span class="sig-name descname"><span class="pre">n_classes</span></span><em class="property"> <span class="pre">:int</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.NIScenario.n_classes" title="Permalink to this definition"></a></dt>
<dd><p>The amount of classes in the original training set.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NIScenario.n_patterns_per_class">
<span class="sig-name descname"><span class="pre">n_patterns_per_class</span></span><em class="property"> <span class="pre">:List[int]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.NIScenario.n_patterns_per_class" title="Permalink to this definition"></a></dt>
<dd><p>The amount of patterns for each class in the original training set.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NIScenario.n_patterns_per_experience">
<span class="sig-name descname"><span class="pre">n_patterns_per_experience</span></span><em class="property"> <span class="pre">:List[int]</span> <span class="pre">=</span> <span class="pre">[]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.NIScenario.n_patterns_per_experience" title="Permalink to this definition"></a></dt>
<dd><p>The number of patterns in each experience.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NIScenario.exp_structure">
<span class="sig-name descname"><span class="pre">exp_structure</span></span><em class="property"> <span class="pre">:List[List[int]]</span> <span class="pre">=</span> <span class="pre">[]</span></em><a class="headerlink" href="#avalanche.benchmarks.scenarios.NIScenario.exp_structure" title="Permalink to this definition"></a></dt>
<dd><p>This field contains, for each training experience, the number of
instances of each class assigned to that experience.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NIScenario.train_exps_patterns_assignment">
<span class="sig-name descname"><span class="pre">train_exps_patterns_assignment</span></span><a class="headerlink" href="#avalanche.benchmarks.scenarios.NIScenario.train_exps_patterns_assignment" title="Permalink to this definition"></a></dt>
<dd><p>A list containing which training instances are assigned to each
experience in the train stream. Instances are identified by their id
w.r.t. the dataset found in the original_train_dataset field.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NIScenario.get_reproducibility_data">
<span class="sig-name descname"><span class="pre">get_reproducibility_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/new_instances/ni_scenario/#NIScenario.get_reproducibility_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.NIScenario.get_reproducibility_data" title="Permalink to this definition"></a></dt>
<dd><p>Gets the data needed to reproduce this experiment.</p>
<p>This data can be stored using the pickle module or some other mechanism.
It can then be loaded by passing it as the <code class="docutils literal notranslate"><span class="pre">reproducibility_data</span></code>
parameter in the constructor.</p>
<p>Child classes should create their own reproducibility dictionary.
This means that the implementation found in <a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericCLScenario" title="avalanche.benchmarks.scenarios.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a>
will return an empty dictionary, which is meaningless.</p>
<p>In order to obtain the same benchmark instance, the reproducibility
data must be passed to the constructor along with the exact same
input datasets.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A dictionary containing the data needed to reproduce the
experiment.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="avalanche.benchmarks.scenarios.NIExperience">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.scenarios.</span></span><span class="sig-name descname"><span class="pre">NIExperience</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">origin_stream</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#avalanche.benchmarks.scenarios.GenericScenarioStream" title="avalanche.benchmarks.scenarios.GenericScenarioStream"><span class="pre">GenericScenarioStream</span></a><span class="p"><span class="pre">[</span></span><span class="pre">'NIExperience'</span><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#avalanche.benchmarks.scenarios.NIScenario" title="avalanche.benchmarks.scenarios.NIScenario"><span class="pre">NIScenario</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_experience</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/benchmarks/scenarios/new_instances/ni_scenario/#NIExperience"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.scenarios.NIExperience" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">GenericExperience[NIScenario,</span> <span class="pre">GenericScenarioStream['NIExperience',</span> <span class="pre">NIScenario]]</span></code></p>
<p>Defines a “New Instances” experience. It defines fields to obtain the
current dataset and the associated task label. It also keeps a reference
to the stream from which this experience was taken.</p>
<p>Creates a <code class="docutils literal notranslate"><span class="pre">NIExperience</span></code> instance given the stream from this
experience was taken and and the current experience ID.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>origin_stream</strong> – The stream from which this experience was
obtained.</p></li>
<li><p><strong>current_experience</strong> – The current experience ID, as an integer.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, ContinualAI.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>