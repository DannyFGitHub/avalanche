<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>avalanche.evaluation.metric_utils &mdash; Avalanche 0.1 documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/mystyle.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex/" />
    <link rel="search" title="Search" href="../../../../search/" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../">
            <img src="../../../../_static/avalanche_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Avalanche API:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../../">API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche</span></code></a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../../#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../../benchmarks/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks</span></code></a></li>
<li class="toctree-l4 current"><a class="reference internal" href="../"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../logging/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.logging</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../models/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.models</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../training/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../#submodules">Submodules</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../core/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.core</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../#package-contents">Package Contents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../#avalanche.__version__">__version__</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../">Avalanche</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../" class="icon icon-home"></a> &raquo;</li>
      <li><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metric_utils</span></code></li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../_sources/autoapi/avalanche/evaluation/metric_utils/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-avalanche.evaluation.metric_utils">
<span id="avalanche-evaluation-metric-utils"></span><h1><a class="reference internal" href="#module-avalanche.evaluation.metric_utils" title="avalanche.evaluation.metric_utils"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metric_utils</span></code></a><a class="headerlink" href="#module-avalanche.evaluation.metric_utils" title="Permalink to this headline"></a></h1>
<section id="module-contents">
<h2>Module Contents<a class="headerlink" href="#module-contents" title="Permalink to this headline"></a></h2>
<section id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Permalink to this headline"></a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metric_utils.default_cm_image_creator" title="avalanche.evaluation.metric_utils.default_cm_image_creator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">default_cm_image_creator</span></code></a>(confusion_matrix_tensor: Tensor, display_labels: Sequence = None, include_values=False, xticks_rotation=0, yticks_rotation=0, values_format=None, cmap='viridis', image_title='')</p></td>
<td><p>The default Confusion Matrix image creator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metric_utils.repartition_pie_chart_image_creator" title="avalanche.evaluation.metric_utils.repartition_pie_chart_image_creator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">repartition_pie_chart_image_creator</span></code></a>(label2counts: Dict[int, List[int]], counters: List[int], colors: Union[ndarray, Iterable, int, float] = SEABORN_COLORS, fmt: str = '%1.1f%%')</p></td>
<td><p>Create a pie chart representing the labels repartition.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metric_utils.repartition_bar_chart_image_creator" title="avalanche.evaluation.metric_utils.repartition_bar_chart_image_creator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">repartition_bar_chart_image_creator</span></code></a>(label2counts: Dict[int, List[int]], counters: List[int], colors: Union[ndarray, Iterable, int, float] = SEABORN_COLORS)</p></td>
<td><p>Create a bar chart representing the labels repartition.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metric_utils.default_history_repartition_image_creator" title="avalanche.evaluation.metric_utils.default_history_repartition_image_creator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">default_history_repartition_image_creator</span></code></a>(label2counts: Dict[int, List[int]], counters: List[int], colors: Union[ndarray, Iterable, int, float] = SEABORN_COLORS)</p></td>
<td><p>Create a stack plot representing the labels repartition with their history.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metric_utils.stream_type" title="avalanche.evaluation.metric_utils.stream_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">stream_type</span></code></a>(experience: Experience) → str</p></td>
<td><p>Returns the stream name from which the experience belongs to.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metric_utils.phase_and_task" title="avalanche.evaluation.metric_utils.phase_and_task"><code class="xref py py-obj docutils literal notranslate"><span class="pre">phase_and_task</span></code></a>(strategy: BaseStrategy) → Tuple[str, int]</p></td>
<td><p>Returns the current phase name and the associated task label.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metric_utils.bytes2human" title="avalanche.evaluation.metric_utils.bytes2human"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bytes2human</span></code></a>(n)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metric_utils.get_metric_name" title="avalanche.evaluation.metric_utils.get_metric_name"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_metric_name</span></code></a>(metric: PluginMetric, strategy: BaseStrategy, add_experience=False, add_task=True)</p></td>
<td><p>Return the complete metric name used to report its current value.</p></td>
</tr>
</tbody>
</table>
<dl class="py function">
<dt class="sig sig-object py" id="avalanche.evaluation.metric_utils.default_cm_image_creator">
<span class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metric_utils.</span></span><span class="sig-name descname"><span class="pre">default_cm_image_creator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">confusion_matrix_tensor</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">display_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_values</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xticks_rotation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">yticks_rotation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'viridis'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_title</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metric_utils/#default_cm_image_creator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metric_utils.default_cm_image_creator" title="Permalink to this definition"></a></dt>
<dd><p>The default Confusion Matrix image creator.
Code adapted from
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html">Scikit learn</a> # noqa</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>confusion_matrix_tensor</strong> – The tensor describing the confusion matrix.
This can be easily obtained through Scikit-learn <cite>confusion_matrix</cite>
utility.</p></li>
<li><p><strong>display_labels</strong> – Target names used for plotting. By default, <cite>labels</cite>
will be used if it is defined, otherwise the values will be inferred by
the matrix tensor.</p></li>
<li><p><strong>include_values</strong> – Includes values in confusion matrix. Defaults to
<cite>False</cite>.</p></li>
<li><p><strong>xticks_rotation</strong> – Rotation of xtick labels. Valid values are
float point value. Defaults to 0.</p></li>
<li><p><strong>yticks_rotation</strong> – Rotation of ytick labels. Valid values are
float point value. Defaults to 0.</p></li>
<li><p><strong>values_format</strong> – Format specification for values in confusion matrix.
Defaults to <cite>None</cite>, which means that the format specification is
‘d’ or ‘.2g’, whichever is shorter.</p></li>
<li><p><strong>cmap</strong> – Must be a str or a Colormap recognized by matplotlib.
Defaults to ‘viridis’.</p></li>
<li><p><strong>image_title</strong> – The title of the image. Defaults to an empty string.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The Confusion Matrix as a PIL Image.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="avalanche.evaluation.metric_utils.repartition_pie_chart_image_creator">
<span class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metric_utils.</span></span><span class="sig-name descname"><span class="pre">repartition_pie_chart_image_creator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label2counts</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">counters</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colors</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span> </span><span class="pre">Iterable</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">SEABORN_COLORS</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fmt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'%1.1f%%'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metric_utils/#repartition_pie_chart_image_creator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metric_utils.repartition_pie_chart_image_creator" title="Permalink to this definition"></a></dt>
<dd><p>Create a pie chart representing the labels repartition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>label2counts</strong> – A dict holding the counts for each label, of the form
{label: [count_at_step_0, count_at_step_1, …]}. Only the last count of
each label is used here.</p></li>
<li><p><strong>counters</strong> – (unused) The steps the counts were taken at.</p></li>
<li><p><strong>colors</strong> – The colors to use in the chart.</p></li>
<li><p><strong>fmt</strong> – Formatting used to display the text values in the chart.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="avalanche.evaluation.metric_utils.repartition_bar_chart_image_creator">
<span class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metric_utils.</span></span><span class="sig-name descname"><span class="pre">repartition_bar_chart_image_creator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label2counts</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">counters</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colors</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span> </span><span class="pre">Iterable</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">SEABORN_COLORS</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metric_utils/#repartition_bar_chart_image_creator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metric_utils.repartition_bar_chart_image_creator" title="Permalink to this definition"></a></dt>
<dd><p>Create a bar chart representing the labels repartition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>label2counts</strong> – A dict holding the counts for each label, of the form
{label: [count_at_step_0, count_at_step_1, …]}. Only the last count of
each label is used here.</p></li>
<li><p><strong>counters</strong> – (unused) The steps the counts were taken at.</p></li>
<li><p><strong>colors</strong> – The colors to use in the chart.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="avalanche.evaluation.metric_utils.default_history_repartition_image_creator">
<span class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metric_utils.</span></span><span class="sig-name descname"><span class="pre">default_history_repartition_image_creator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label2counts</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">counters</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colors</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span> </span><span class="pre">Iterable</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">SEABORN_COLORS</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metric_utils/#default_history_repartition_image_creator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metric_utils.default_history_repartition_image_creator" title="Permalink to this definition"></a></dt>
<dd><p>Create a stack plot representing the labels repartition with their history.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>label2counts</strong> – A dict holding the counts for each label, of the form
{label: [count_at_step_0, count_at_step_1, …]}.</p></li>
<li><p><strong>counters</strong> – The steps the counts were taken at.</p></li>
<li><p><strong>colors</strong> – The colors to use in the chart.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="avalanche.evaluation.metric_utils.stream_type">
<span class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metric_utils.</span></span><span class="sig-name descname"><span class="pre">stream_type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">experience</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Experience</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metric_utils/#stream_type"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metric_utils.stream_type" title="Permalink to this definition"></a></dt>
<dd><p>Returns the stream name from which the experience belongs to.
e.g. the experience can be part of train or test stream.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>experience</strong> – the instance of the experience</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="avalanche.evaluation.metric_utils.phase_and_task">
<span class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metric_utils.</span></span><span class="sig-name descname"><span class="pre">phase_and_task</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metric_utils/#phase_and_task"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metric_utils.phase_and_task" title="Permalink to this definition"></a></dt>
<dd><p>Returns the current phase name and the associated task label.</p>
<p>The current task label depends on the phase. During the training
phase, the task label is the one defined in the “train_task_label”
field. On the contrary, during the eval phase the task label is the one
defined in the “eval_task_label” field.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>strategy</strong> – The strategy instance to get the task label from.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The current phase name as either “Train” or “Task” and the
associated task label.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="avalanche.evaluation.metric_utils.bytes2human">
<span class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metric_utils.</span></span><span class="sig-name descname"><span class="pre">bytes2human</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metric_utils/#bytes2human"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metric_utils.bytes2human" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="avalanche.evaluation.metric_utils.get_metric_name">
<span class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metric_utils.</span></span><span class="sig-name descname"><span class="pre">get_metric_name</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">PluginMetric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_experience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_task</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metric_utils/#get_metric_name"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metric_utils.get_metric_name" title="Permalink to this definition"></a></dt>
<dd><p>Return the complete metric name used to report its current value.
The name is composed by:
metric string representation /phase type/stream type/task id
where metric string representation is a synthetic string
describing the metric, phase type describe if the user
is training (train) or evaluating (eval), stream type describes
the type of stream the current experience belongs to (e.g. train, test)
and task id is the current task label.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metric</strong> – the metric object for which return the complete name</p></li>
<li><p><strong>strategy</strong> – the current strategy object</p></li>
<li><p><strong>add_experience</strong> – if True, add eval_exp_id to the main metric name.
Default to False.</p></li>
<li><p><strong>add_task</strong> – if True the main metric name will include the task
information. If False, no task label will be displayed.
If an int, that value will be used as task label for the metric name.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, ContinualAI.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>